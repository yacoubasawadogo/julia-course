# Practice 11.2 : Classification de Messages en Langues Locales du Burkina Faso

## üéØ Objectif
D√©velopper un syst√®me de classification automatique pour identifier la langue et le sentiment de messages texte en langues nationales du Burkina Faso (Moor√©, Dioula, Fulfuld√©). Ce syst√®me sera utile pour analyser les r√©seaux sociaux, enqu√™tes d'opinion et communications gouvernementales.

## üìã Pr√©requis
```julia
using MLJ
using DataFrames
using Statistics
using Random
using StatsBase
using TextAnalysis

# Mod√®les de classification
MultinomialClassifier = @load MultinomialNB pkg=MLJNaiveBayesInterface
DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree
LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels

Random.seed!(2024)
```

## üó£Ô∏è Phase 1: Cr√©ation du Dataset Linguistique

### √âtape 1: Construction du corpus multilingue
```julia
# Dataset de messages en langues locales du Burkina Faso
function create_multilingual_dataset(n_messages=1000)
    
    # Vocabulaire de base par langue avec traductions approximatives
    vocabulaire = Dict(
        "Moore" => Dict(
            "salutations" => ["Yaa sooma", "Mba ne o sida", "Kumyaare", "Laafi bala", "Yamba"],
            "famille" => ["maama", "taaba", "biiga", "pugsisi", "paga", "sabtaaba"],
            "nourriture" => ["baam", "zom", "tuum", "noom", "saaga"],
            "emotions_positives" => ["raab seb", "wend raab", "koe raab", "n raab", "wendpuiri"],
            "emotions_negatives" => ["n biiga", "sukuru", "tanbsgo", "ye n biigiame"],
            "agriculture" => ["bugum", "naab tuum", "suka", "naab saaga", "koose"],
            "climat" => ["sugur", "saam", "kiuuri", "yuuni", "kibse"],
            "sante" => ["laafi", "bukone", "tibo", "laafimi", "yiibu"],
            "politique" => ["naaba", "naam", "pugsaandame", "naabdem"],
            "connecteurs" => ["la", "ye", "ka", "fo", "n", "be", "taa"]
        ),
        "Dioula" => Dict(
            "salutations" => ["I ni tile", "I ni sogoma", "Aw ni tile", "A ka kene", "I ni wula"],
            "famille" => ["fa", "ba", "muso", "denmuso", "den", "denke"],
            "nourriture" => ["dumuni", "nkomi", "malo", "taba", "ji"],
            "emotions_positives" => ["a ka nyi", "nisongoya", "a ka fisa", "m'bi fara"],
            "emotions_negatives" => ["jugu", "a tere n na", "tiiriya", "dimi"],
            "agriculture" => ["sene", "sanji", "nak…î", "jiri", "seni"],
            "climat" => ["san", "k…îr…în", "dugukuru", "fi…≤…≤e"],
            "sante" => ["keneya", "banani", "d…îg…ît…îr…î", "furak…õ…≤…õ"],
            "politique" => ["mansa", "jamunad…în", "fasow", "laadi"],
            "connecteurs" => ["ni", "wa", "ka", "fo", "ye", "la", "k…î"]
        ),
        "Fulfuld√©" => Dict(
            "salutations" => ["Jam tan", "Jam walli", "No mbadda", "∆äum jaraama", "Jam weeti"],
            "famille" => ["baaba", "nene", "sukaaku", "rew…ìe", "mayre"],
            "nourriture" => ["nyaamdu", "njabbu", "laam", "kosam", "ndiyam"],
            "emotions_positives" => ["mi ja…ìii", "e ya…ìata", "renndo", "sukaa…ìe"],
            "emotions_negatives" => ["mi …ìernini", "ha…ì…ìude", "ceendu", "ndaar"],
            "agriculture" => ["…ìi…ó…óo", "lekki", "naange", "nyaamewal"],
            "climat" => ["see…óa", "…óemngal", "yamru", "pelle"],
            "sante" => ["paggude", "jaango", "dokotoor", "yiiteende"],
            "politique" => ["laam…óo", "laamu", "leydi", "hoore"],
            "connecteurs" => ["e", "kaa", "to", "faa", "bee", "nde", "hay"]
        )
    )
    
    # Messages types par cat√©gorie
    patterns_messages = [
        # Salutations et politesse
        ("greeting", ["salutations", "connecteurs", "famille"]),
        # Agriculture et √©conomie  
        ("agriculture", ["agriculture", "climat", "emotions_positives", "connecteurs"]),
        # Sant√© et bien-√™tre
        ("health", ["sante", "emotions_positives", "famille", "connecteurs"]),
        # Politique et soci√©t√©
        ("politics", ["politique", "connecteurs", "emotions_negatives"]),
        # Vie quotidienne
        ("daily_life", ["nourriture", "famille", "emotions_positives", "connecteurs"])
    ]
    
    # Messages avec sentiment
    sentiments = ["positif", "negatif", "neutre"]
    
    data = []
    
    for i in 1:n_messages
        # S√©lection al√©atoire de langue et cat√©gorie
        langue = rand(["Moore", "Dioula", "Fulfuld√©"])
        categorie, champs = rand(patterns_messages)
        sentiment = rand(sentiments)
        
        # Construction du message
        mots = String[]
        n_mots = rand(3:12)  # Longueur variable du message
        
        for j in 1:n_mots
            champ = rand(champs)
            if haskey(vocabulaire[langue], champ) && !isempty(vocabulaire[langue][champ])
                mot = rand(vocabulaire[langue][champ])
                push!(mots, mot)
            end
        end
        
        # Ajustement selon le sentiment
        if sentiment == "positif" && haskey(vocabulaire[langue], "emotions_positives")
            push!(mots, rand(vocabulaire[langue]["emotions_positives"]))
        elseif sentiment == "negatif" && haskey(vocabulaire[langue], "emotions_negatives")
            push!(mots, rand(vocabulaire[langue]["emotions_negatives"]))
        end
        
        message = join(mots, " ")
        
        # Ajout de variabilit√© (r√©p√©titions, ponctuation)
        if rand() < 0.3
            message = message * " " * rand(mots)  # R√©p√©tition d'un mot
        end
        
        if rand() < 0.2
            message = message * "!"
        elseif rand() < 0.1
            message = message * "?"
        end
        
        push!(data, (
            message = message,
            langue = langue,
            categorie = categorie,
            sentiment = sentiment,
            longueur_mots = length(mots),
            longueur_caracteres = length(message)
        ))
    end
    
    return DataFrame(data)
end

# Cr√©ation du dataset
df_messages = create_multilingual_dataset(1200)

println("üì± Dataset de messages cr√©√© :")
println("üìä Total messages : $(nrow(df_messages))")
println("üó£Ô∏è R√©partition par langue :")
println(countmap(df_messages.langue))
println("üìñ R√©partition par cat√©gorie :")
println(countmap(df_messages.categorie))
println("üí≠ R√©partition par sentiment :")
println(countmap(df_messages.sentiment))
```

**üéØ D√©fi 1 :** Explorez la distribution des longueurs de messages et identifiez les patterns par langue.

---

### √âtape 2: Enrichissement avec des messages r√©alistes
```julia
# Ajout de messages plus complexes et r√©alistes
messages_realistes = [
    # Moor√© - Agriculture
    ("Moore", "Naab tuum ra yaa ka suka la tuum woto raab seb", "agriculture", "positif"),
    ("Moore", "Sugur koese la n biiga fo bug tuum ye poor", "agriculture", "negatif"),
    ("Moore", "Wend puiri naab saaga la market price ka raab", "agriculture", "positif"),
    
    # Dioula - Politique  
    ("Dioula", "Mansa ka jamunad…în caman k…õ wa fasow la", "politics", "neutre"),
    ("Dioula", "Laadi ninnu t…õ ka …≤i wa a ka tiiriya d…în", "politics", "negatif"),
    ("Dioula", "D…îg…ît…îr…î ka nyi jamana keneya hakili la", "politics", "positif"),
    
    # Fulfuld√© - Sant√©
    ("Fulfuld√©", "Dokotoor ka wi jaango paggude hoore men", "health", "positif"),
    ("Fulfuld√©", "Mi …ìernini ko yiiteende ndaar ka tawi", "health", "negatif"),
    ("Fulfuld√©", "Laam be nyaamdu renndo sukaa…ìe bee", "health", "positif"),
    
    # Messages m√©lang√©s (code-switching)
    ("Moore", "Yaa sooma doctor ba n ti hospital", "health", "neutre"),
    ("Dioula", "I ni tile ka market ka nkomi san", "daily_life", "neutre"),
    ("Fulfuld√©", "Jam tan mama ko …ìi…ó…óo lekki", "greeting", "positif")
]

# Ajout au dataset principal
for (langue, message, categorie, sentiment) in messages_realistes
    push!(df_messages, (
        message = message,
        langue = langue, 
        categorie = categorie,
        sentiment = sentiment,
        longueur_mots = length(split(message)),
        longueur_caracteres = length(message)
    ))
end

println("üìù Dataset enrichi : $(nrow(df_messages)) messages")
```

**üéØ D√©fi 2 :** Ajoutez 10 messages r√©alistes suppl√©mentaires dans chaque langue.

---

### √âtape 3: Pr√©paration des features textuelles
```julia
# Fonction pour extraire des features textuelles
function extraire_features_textuelles(messages::Vector{String})
    features = DataFrame()
    
    # Features de base
    features.longueur_mots = [length(split(msg)) for msg in messages]
    features.longueur_caracteres = [length(msg) for msg in messages]
    features.mots_moyens_longueur = [mean(length.(split(msg))) for msg in messages]
    
    # Features de ponctuation
    features.nb_exclamations = [count("!", msg) for msg in messages]
    features.nb_questions = [count("?", msg) for msg in messages]
    features.nb_espaces = [count(" ", msg) for msg in messages]
    
    # Features linguistiques (pr√©sence de caract√®res sp√©ciaux)
    features.a_accents = [any(c in msg for c in "√†√°√¢√£√§√•√¶√ß√®√©√™√´√¨√≠√Æ√Ø√±√≤√≥√¥√µ√∂√∏√π√∫√ª√º√Ω") for msg in messages]
    features.a_caracteres_speciaux = [any(c in msg for c in "…ì…ó≈ã…≤…î…õ") for msg in messages]
    
    # N-grammes de caract√®res (signatures linguistiques)
    # Bigrams caract√©ristiques par langue
    bigrams_moore = ["aa", "ii", "uu", "gb", "kg", "ng"]
    bigrams_dioula = ["ni", "ka", "la", "an", "…în", "…õn"]
    bigrams_fulfilde = ["ee", "aa", "…ì…ì", "…ó…ó", "ng", "mb"]
    
    for bigram in bigrams_moore
        features[!, Symbol("bg_moore_" * bigram)] = [count(bigram, lowercase(msg)) for msg in messages]
    end
    
    for bigram in bigrams_dioula  
        features[!, Symbol("bg_dioula_" * bigram)] = [count(bigram, lowercase(msg)) for msg in messages]
    end
    
    for bigram in bigrams_fulfilde
        features[!, Symbol("bg_fulfilde_" * bigram)] = [count(bigram, lowercase(msg)) for msg in messages]
    end
    
    # Mots caract√©ristiques par langue
    mots_cles = Dict(
        "moore" => ["yaa", "mba", "wend", "naab", "raab", "laafi"],
        "dioula" => ["tile", "sogoma", "kene", "mansa", "jamana"],
        "fulfilde" => ["jam", "jaraama", "laam", "renndo", "sukaa"]
    )
    
    for (langue, mots) in mots_cles
        for mot in mots
            features[!, Symbol("mot_" * langue * "_" * mot)] = [
                count(mot, lowercase(msg)) for msg in messages
            ]
        end
    end
    
    return features
end

# Extraction des features
X_text = extraire_features_textuelles(df_messages.message)

println("üîç Features textuelles extraites :")
println("üìä Nombre de features : $(ncol(X_text))")
println("üìù Features : $(names(X_text)[1:10])...")  # Premi√®re 10 features
```

**üéØ D√©fi 3 :** Analysez quelles features sont les plus discriminantes entre les langues.

---

## üéØ Phase 2: Classification de Langues

### √âtape 4: Mod√®le de d√©tection de langue
```julia
# Pr√©paration des donn√©es pour classification de langue
y_langue = categorical(df_messages.langue)

# Division train/test
train_indices, test_indices = partition(eachindex(y_langue), 0.75, shuffle=true, rng=42)

X_train_lang = X_text[train_indices, :]
X_test_lang = X_text[test_indices, :]
y_train_lang = y_langue[train_indices]
y_test_lang = y_langue[test_indices]

println("üìä Division des donn√©es - D√©tection de langue :")
println("Train : $(length(train_indices)) messages")
println("Test : $(length(test_indices)) messages")

# Test de plusieurs mod√®les pour la d√©tection de langue
modeles_langue = [
    ("Naive Bayes", MultinomialClassifier()),
    ("Logistic Regression", LogisticClassifier()),
    ("Decision Tree", DecisionTreeClassifier(max_depth=10))
]

resultats_langue = DataFrame()

for (nom_modele, modele) in modeles_langue
    println("\nüöÄ Entra√Ænement $nom_modele pour d√©tection de langue...")
    
    # Entra√Ænement
    machine_lang = machine(modele, X_train_lang, y_train_lang)
    fit!(machine_lang, verbosity=0)
    
    # Pr√©dictions
    y_pred_train = predict_mode(machine_lang, X_train_lang)
    y_pred_test = predict_mode(machine_lang, X_test_lang)
    
    # M√©triques
    accuracy_train = mean(y_pred_train .== y_train_lang)
    accuracy_test = mean(y_pred_test .== y_test_lang)
    
    println("Accuracy train : $(round(accuracy_train, digits=3))")
    println("Accuracy test : $(round(accuracy_test, digits=3))")
    
    # Matrice de confusion
    conf_matrix = confusion_matrix(y_pred_test, y_test_lang)
    println("Matrice de confusion :")
    println(conf_matrix)
    
    push!(resultats_langue, (
        modele = nom_modele,
        accuracy_train = accuracy_train,
        accuracy_test = accuracy_test,
        overfitting = accuracy_train - accuracy_test
    ))
end

println("\nüìä R√©sum√© des performances - D√©tection de langue :")
println(resultats_langue)
```

**üéØ D√©fi 4 :** Quel mod√®le performe le mieux ? Y a-t-il de l'overfitting ?

---

### √âtape 5: Analyse des erreurs de classification
```julia
# Analyse d√©taill√©e avec le meilleur mod√®le (supposons Logistic Regression)
best_model_lang = LogisticClassifier()
best_machine_lang = machine(best_model_lang, X_train_lang, y_train_lang)
fit!(best_machine_lang, verbosity=0)

y_pred_best = predict_mode(best_machine_lang, X_test_lang)

# Analyse des erreurs
function analyser_erreurs_classification(y_true, y_pred, messages_test, langues_test)
    erreurs = y_true .!= y_pred
    indices_erreurs = findall(erreurs)
    
    println("üîç Analyse des erreurs de classification :")
    println("Nombre d'erreurs : $(sum(erreurs)) sur $(length(y_true))")
    
    if length(indices_erreurs) > 0
        println("\nExemples d'erreurs :")
        for i in indices_erreurs[1:min(5, length(indices_erreurs))]
            vraie_langue = y_true[i]
            pred_langue = y_pred[i]
            message = messages_test[i]
            
            println("Message : \"$message\"")
            println("Vraie langue : $vraie_langue | Pr√©dite : $pred_langue")
            println("---")
        end
    end
    
    # Matrice de confusion d√©taill√©e
    conf_matrix = confusion_matrix(y_pred, y_true)
    return conf_matrix
end

messages_test = df_messages.message[test_indices]
conf_mat = analyser_erreurs_classification(y_test_lang, y_pred_best, messages_test, y_test_lang)
```

**üéØ D√©fi 5 :** Identifiez les patterns dans les erreurs. Quels types de messages sont mal classifi√©s ?

---

## üí≠ Phase 3: Classification de Sentiment

### √âtape 6: Mod√®le de d√©tection de sentiment
```julia
# Classification de sentiment (positif/n√©gatif/neutre)
y_sentiment = categorical(df_messages.sentiment)

# Division train/test pour sentiment
X_train_sent = X_text[train_indices, :]
X_test_sent = X_text[test_indices, :]
y_train_sent = y_sentiment[train_indices]
y_test_sent = y_sentiment[test_indices]

# Ajout de features sp√©cifiques au sentiment
function extraire_features_sentiment(messages::Vector{String})
    features_sent = DataFrame()
    
    # Mots positifs/n√©gatifs par langue
    mots_positifs = ["raab", "kene", "nisongoya", "renndo", "sukaa", "wend", "ja…ìii"]
    mots_negatifs = ["biiga", "sukuru", "jugu", "tiiriya", "…ìernini", "ha…ì…ìude", "ndaar"]
    
    features_sent.nb_mots_positifs = [
        sum(count(mot, lowercase(msg)) for mot in mots_positifs) for msg in messages
    ]
    
    features_sent.nb_mots_negatifs = [
        sum(count(mot, lowercase(msg)) for mot in mots_negatifs) for msg in messages
    ]
    
    features_sent.ratio_positif_negatif = [
        pos == 0 && neg == 0 ? 0.0 : pos / (pos + neg + 1) 
        for (pos, neg) in zip(features_sent.nb_mots_positifs, features_sent.nb_mots_negatifs)
    ]
    
    # Ponctuation √©motionnelle
    features_sent.intensite_ponctuation = [
        count("!", msg) + count("?", msg) * 0.5 for msg in messages
    ]
    
    return features_sent
end

# Combinaison des features textuelles et sentiment
X_sent_features = extraire_features_sentiment(df_messages.message)
X_combined_train = hcat(X_train_sent, X_sent_features[train_indices, :])
X_combined_test = hcat(X_test_sent, X_sent_features[test_indices, :])

# Entra√Ænement des mod√®les pour sentiment
modeles_sentiment = [
    ("Naive Bayes", MultinomialClassifier()),
    ("Logistic Regression", LogisticClassifier()),
    ("Decision Tree", DecisionTreeClassifier(max_depth=8))
]

resultats_sentiment = DataFrame()

for (nom_modele, modele) in modeles_sentiment
    println("\nüé≠ Entra√Ænement $nom_modele pour d√©tection de sentiment...")
    
    # Entra√Ænement
    machine_sent = machine(modele, X_combined_train, y_train_sent)
    fit!(machine_sent, verbosity=0)
    
    # Pr√©dictions
    y_pred_sent_test = predict_mode(machine_sent, X_combined_test)
    
    # M√©triques
    accuracy_sent = mean(y_pred_sent_test .== y_test_sent)
    
    println("Accuracy sentiment : $(round(accuracy_sent, digits=3))")
    
    # M√©triques par classe
    for sentiment in ["positif", "negatif", "neutre"]
        indices_classe = y_test_sent .== sentiment
        if sum(indices_classe) > 0
            accuracy_classe = mean(y_pred_sent_test[indices_classe] .== y_test_sent[indices_classe])
            println("Accuracy $sentiment : $(round(accuracy_classe, digits=3))")
        end
    end
    
    push!(resultats_sentiment, (
        modele = nom_modele,
        accuracy_global = accuracy_sent
    ))
end

println("\nüìä R√©sum√© des performances - D√©tection de sentiment :")
println(resultats_sentiment)
```

**üéØ D√©fi 6 :** Le sentiment est-il plus difficile √† d√©tecter que la langue ? Pourquoi ?

---

### √âtape 7: Classification multi-t√¢che (langue + sentiment)
```julia
# Mod√®le qui pr√©dit √† la fois langue et sentiment
function classifier_multitache(X_train, y_train_lang, y_train_sent, X_test)
    # Mod√®le pour langue
    model_lang = LogisticClassifier()
    machine_lang = machine(model_lang, X_train, y_train_lang)
    fit!(machine_lang, verbosity=0)
    
    # Mod√®le pour sentiment
    model_sent = LogisticClassifier()
    machine_sent = machine(model_sent, X_train, y_train_sent)
    fit!(machine_sent, verbosity=0)
    
    # Pr√©dictions
    pred_lang = predict_mode(machine_lang, X_test)
    pred_sent = predict_mode(machine_sent, X_test)
    
    return pred_lang, pred_sent, machine_lang, machine_sent
end

# Application de la classification multi-t√¢che
pred_lang_multi, pred_sent_multi, mach_lang, mach_sent = classifier_multitache(
    X_combined_train, y_train_lang, y_train_sent, X_combined_test
)

# √âvaluation combin√©e
accuracy_lang_multi = mean(pred_lang_multi .== y_test_lang)
accuracy_sent_multi = mean(pred_sent_multi .== y_test_sent)

# Accuracy pour pr√©diction exacte des deux t√¢ches
accuracy_both = mean((pred_lang_multi .== y_test_lang) .& (pred_sent_multi .== y_test_sent))

println("üéØ Performance multi-t√¢che :")
println("Accuracy langue : $(round(accuracy_lang_multi, digits=3))")
println("Accuracy sentiment : $(round(accuracy_sent_multi, digits=3))")
println("Accuracy les deux : $(round(accuracy_both, digits=3))")
```

**üéØ D√©fi 7 :** La performance multi-t√¢che est-elle satisfaisante pour une application r√©elle ?

---

## üì± Phase 4: Application Pratique

### √âtape 8: Syst√®me de mod√©ration automatique
```julia
# Fonction de mod√©ration de contenu
function moderer_message(message::String, machine_lang, machine_sent, seuil_confiance=0.7)
    # Extraction des features pour le nouveau message
    features_msg = extraire_features_textuelles([message])
    features_sent_msg = extraire_features_sentiment([message])
    features_combined = hcat(features_msg, features_sent_msg)
    
    # Pr√©dictions avec probabilit√©s
    prob_lang = predict(machine_lang, features_combined)
    prob_sent = predict(machine_sent, features_combined)
    
    # Langue pr√©dite
    pred_lang = predict_mode(machine_lang, features_combined)[1]
    conf_lang = maximum([prob.prob_given_ref[2] for prob in prob_lang])
    
    # Sentiment pr√©dit
    pred_sent = predict_mode(machine_sent, features_combined)[1]
    conf_sent = maximum([prob.prob_given_ref[2] for prob in prob_sent])
    
    # D√©cision de mod√©ration
    moderation_flags = []
    
    if conf_lang < seuil_confiance
        push!(moderation_flags, "langue_incertaine")
    end
    
    if conf_sent < seuil_confiance
        push!(moderation_flags, "sentiment_incertain")
    end
    
    if pred_sent == "negatif" && conf_sent > 0.8
        push!(moderation_flags, "contenu_potentiellement_negatif")
    end
    
    return Dict(
        "message" => message,
        "langue_predite" => pred_lang,
        "confiance_langue" => round(conf_lang, digits=3),
        "sentiment_predit" => pred_sent,
        "confiance_sentiment" => round(conf_sent, digits=3),
        "flags_moderation" => moderation_flags,
        "necessite_revision_humaine" => length(moderation_flags) > 0
    )
end

# Test du syst√®me de mod√©ration
messages_test_moderation = [
    "Yaa sooma naab tuum ka raab seb",  # Moor√© positif
    "Mansa ka jamunad…în jugu don wa",   # Dioula n√©gatif
    "Jam tan dokotoor paggude men",     # Fulfuld√© neutre
    "Hello comment allez-vous today"    # Message mixte (test)
]

println("üõ°Ô∏è Test du syst√®me de mod√©ration :")
for msg in messages_test_moderation
    resultat = moderer_message(msg, mach_lang, mach_sent)
    println("\nMessage : \"$(resultat["message"])\"")
    println("Langue : $(resultat["langue_predite"]) (conf: $(resultat["confiance_langue"]))")
    println("Sentiment : $(resultat["sentiment_predit"]) (conf: $(resultat["confiance_sentiment"]))")
    println("Flags : $(resultat["flags_moderation"])")
    println("R√©vision humaine : $(resultat["necessite_revision_humaine"])")
end
```

**üéØ D√©fi 8 :** Testez le syst√®me avec vos propres messages dans les langues locales.

---

### √âtape 9: Analyse de tendances linguistiques
```julia
# Fonction d'analyse de tendances pour un corpus de messages
function analyser_tendances_corpus(messages::Vector{String}, machine_lang, machine_sent)
    
    # Classification de tous les messages
    features_corpus = extraire_features_textuelles(messages)
    features_sent_corpus = extraire_features_sentiment(messages)
    features_combined_corpus = hcat(features_corpus, features_sent_corpus)
    
    pred_langues = predict_mode(machine_lang, features_combined_corpus)
    pred_sentiments = predict_mode(machine_sent, features_combined_corpus)
    
    # Statistiques g√©n√©rales
    stats_langues = countmap(pred_langues)
    stats_sentiments = countmap(pred_sentiments)
    
    println("üìä Analyse du corpus ($(length(messages)) messages) :")
    println("\nüó£Ô∏è R√©partition des langues :")
    for (langue, count) in sort(collect(stats_langues), by=x->x[2], rev=true)
        pourcentage = round(count / length(messages) * 100, digits=1)
        println("  $langue : $count messages ($(pourcentage)%)")
    end
    
    println("\nüí≠ R√©partition des sentiments :")
    for (sentiment, count) in sort(collect(stats_sentiments), by=x->x[2], rev=true)
        pourcentage = round(count / length(messages) * 100, digits=1)
        println("  $sentiment : $count messages ($(pourcentage)%)")
    end
    
    # Analyse crois√©e langue-sentiment
    println("\nüîÑ Croisement langue-sentiment :")
    for langue in unique(pred_langues)
        indices_langue = pred_langues .== langue
        if sum(indices_langue) > 0
            sentiments_langue = pred_sentiments[indices_langue]
            stats_sent_langue = countmap(sentiments_langue)
            
            println("  $langue :")
            for (sentiment, count) in stats_sent_langue
                pourcentage = round(count / sum(indices_langue) * 100, digits=1)
                println("    $sentiment : $(pourcentage)%")
            end
        end
    end
    
    return Dict(
        "langues" => stats_langues,
        "sentiments" => stats_sentiments,
        "predictions_langue" => pred_langues,
        "predictions_sentiment" => pred_sentiments
    )
end

# Test sur notre corpus
resultats_tendances = analyser_tendances_corpus(df_messages.message, mach_lang, mach_sent)
```

**üéØ D√©fi 9 :** Quelle langue semble avoir le sentiment le plus positif dans votre corpus ?

---

### √âtape 10: D√©tection de messages urgents/prioritaires
```julia
# Syst√®me de priorisation de messages
function detecter_urgence_message(message::String, machine_lang, machine_sent)
    
    # Mots-cl√©s d'urgence par domaine
    mots_urgence = Dict(
        "sante" => ["dokotoor", "d…îg…ît…îr…î", "tibo", "banani", "jaango", "bukone"],
        "securite" => ["police", "gendarme", "j…îr…î", "ha…ì…ìude", "danger"],
        "catastrophe" => ["feu", "ta", "flood", "banga", "accident"],
        "agriculture" => ["koose", "famine", "tanbsgo", "suka poor", "naab tuum"]
    )
    
    # Score d'urgence de base
    score_urgence = 0.0
    domaines_detectes = []
    
    message_lower = lowercase(message)
    
    # D√©tection par mots-cl√©s
    for (domaine, mots) in mots_urgence
        for mot in mots
            if occursin(mot, message_lower)
                score_urgence += 1.0
                push!(domaines_detectes, domaine)
                break  # Un domaine par cat√©gorie maximum
            end
        end
    end
    
    # Ajustement selon le sentiment
    features_msg = extraire_features_textuelles([message])
    features_sent_msg = extraire_features_sentiment([message])
    features_combined = hcat(features_msg, features_sent_msg)
    
    pred_sent = predict_mode(machine_sent, features_combined)[1]
    
    if pred_sent == "negatif"
        score_urgence += 0.5
    end
    
    # Ajustement selon la ponctuation
    if count("!", message) > 1
        score_urgence += 0.3
    end
    
    # Classification de priorit√©
    priorite = score_urgence >= 2.0 ? "HAUTE" :
              score_urgence >= 1.0 ? "MOYENNE" : "BASSE"
    
    return Dict(
        "message" => message,
        "score_urgence" => score_urgence,
        "priorite" => priorite,
        "domaines_detectes" => unique(domaines_detectes),
        "sentiment" => pred_sent,
        "necessite_attention_immediate" => score_urgence >= 2.0
    )
end

# Test du syst√®me de d√©tection d'urgence
messages_urgence_test = [
    "Dokotoor ka wi mi ja…ìii paggude hoore",      # Sant√©, positif
    "N biiga tibo ka poor sukuru naab tuum",      # Agriculture + sant√©, n√©gatif  
    "Yaa sooma laafi bala wend puiri",            # Salutation normale
    "D…îg…ît…îr…î! Banani jugu don wa fasa!",         # Sant√© urgente !
    "Ta d…în wa! Ha…ì…ìude bee sukaa…ìe!"             # Catastrophe !
]

println("üö® Test de d√©tection d'urgence :")
for msg in messages_urgence_test
    urgence = detecter_urgence_message(msg, mach_lang, mach_sent)
    println("\nMessage : \"$(urgence["message"])\"")
    println("Priorit√© : $(urgence["priorite"]) (score: $(urgence["score_urgence"]))")
    println("Domaines : $(urgence["domaines_detectes"])")
    println("Sentiment : $(urgence["sentiment"])")
    println("Attention imm√©diate : $(urgence["necessite_attention_immediate"])")
end
```

**üéØ D√©fi 10 :** Enrichissez le dictionnaire de mots d'urgence avec des termes sp√©cifiques au contexte burkinab√®.

---

### √âtape 11: Interface de traitement en lot
```julia
# Fonction de traitement en lot pour analyse de r√©seaux sociaux
function traiter_corpus_reseaux_sociaux(messages::Vector{String}, machine_lang, machine_sent)
    
    println("üîÑ Traitement en cours de $(length(messages)) messages...")
    
    # Traitement de tous les messages
    features_lot = extraire_features_textuelles(messages)
    features_sent_lot = extraire_features_sentiment(messages)
    features_combined_lot = hcat(features_lot, features_sent_lot)
    
    # Pr√©dictions en lot
    pred_langues_lot = predict_mode(machine_lang, features_combined_lot)
    pred_sentiments_lot = predict_mode(machine_sent, features_combined_lot)
    prob_langues_lot = predict(machine_lang, features_combined_lot)
    prob_sentiments_lot = predict(machine_sent, features_combined_lot)
    
    # Cr√©ation du rapport d√©taill√©
    rapport = DataFrame(
        message = messages,
        langue_predite = pred_langues_lot,
        sentiment_predit = pred_sentiments_lot,
        confiance_langue = [maximum([p.prob_given_ref[2] for p in prob]) for prob in prob_langues_lot],
        confiance_sentiment = [maximum([p.prob_given_ref[2] for p in prob]) for prob in prob_sentiments_lot],
        longueur_mots = [length(split(msg)) for msg in messages],
        contient_urgence = [detecter_urgence_message(msg, machine_lang, machine_sent)["priorite"] != "BASSE" for msg in messages]
    )
    
    # Statistiques globales
    println("\nüìä R√©sultats du traitement :")
    println("Messages analys√©s : $(nrow(rapport))")
    println("Langues d√©tect√©es : $(length(unique(rapport.langue_predite)))")
    println("Messages urgents/prioritaires : $(sum(rapport.contient_urgence))")
    
    # Top langues
    top_langues = sort(collect(countmap(rapport.langue_predite)), by=x->x[2], rev=true)
    println("\nTop 3 langues :")
    for (i, (langue, count)) in enumerate(top_langues[1:min(3, length(top_langues))])
        pourcentage = round(count / nrow(rapport) * 100, digits=1)
        println("$i. $langue : $count messages ($(pourcentage)%)")
    end
    
    # Distribution sentiment
    sentiment_dist = countmap(rapport.sentiment_predit)
    println("\nDistribution des sentiments :")
    for (sentiment, count) in sentiment_dist
        pourcentage = round(count / nrow(rapport) * 100, digits=1)
        println("$sentiment : $(pourcentage)%")
    end
    
    # Messages √† faible confiance (n√©cessitent r√©vision)
    low_confidence = sum((rapport.confiance_langue .< 0.7) .| (rapport.confiance_sentiment .< 0.7))
    println("\nMessages n√©cessitant r√©vision humaine : $low_confidence ($(round(low_confidence/nrow(rapport)*100, digits=1))%)")
    
    return rapport
end

# Test avec un √©chantillon de messages
echantillon_messages = df_messages.message[1:50]  # Premier 50 messages
rapport_analyse = traiter_corpus_reseaux_sociaux(echantillon_messages, mach_lang, mach_sent)

# Sauvegarde du rapport (simulation)
println("\nüíæ Rapport sauvegard√© : rapport_analyse_$(Dates.today()).csv")
```

**üéØ D√©fi 11 :** Analysez les messages √† faible confiance. Quels patterns observez-vous ?

---

### √âtape 12: √âvaluation de l'impact soci√©tal
```julia
# Analyse de l'impact potentiel du syst√®me
function evaluer_impact_societal()
    println("üåç √âVALUATION DE L'IMPACT SOCI√âTAL")
    println("=" * 50)
    
    # M√©triques de performance du syst√®me
    accuracy_lang_finale = accuracy_lang_multi
    accuracy_sent_finale = accuracy_sent_multi
    
    println("üìä PERFORMANCE TECHNIQUE :")
    println("Pr√©cision d√©tection langue : $(round(accuracy_lang_finale * 100, digits=1))%")
    println("Pr√©cision d√©tection sentiment : $(round(accuracy_sent_finale * 100, digits=1))%")
    
    # Estimation de l'utilit√©
    println("\nüéØ APPLICATIONS POTENTIELLES :")
    applications = [
        "Mod√©ration automatique des r√©seaux sociaux",
        "Analyse de l'opinion publique multilingue", 
        "Syst√®me d'alerte pr√©coce pour services d'urgence",
        "Support client multilingue automatis√©",
        "Recherche en linguistique des langues nationales",
        "Pr√©servation et documentation des langues locales"
    ]
    
    for (i, app) in enumerate(applications)
        println("$i. $app")
    end
    
    # Consid√©rations √©thiques
    println("\n‚ö†Ô∏è CONSID√âRATIONS √âTHIQUES :")
    considerations = [
        "Biais potentiel envers certaines variantes dialectales",
        "Risque de sur-mod√©ration de contenus l√©gitimes",
        "Protection de la vie priv√©e des utilisateurs",
        "N√©cessit√© de r√©vision humaine pour d√©cisions importantes",
        "Impact sur l'emploi des mod√©rateurs humains",
        "Repr√©sentativit√© √©quitable des diff√©rentes communaut√©s"
    ]
    
    for (i, consideration) in enumerate(considerations)
        println("$i. $consideration")
    end
    
    # Recommandations d'am√©lioration
    println("\nüöÄ RECOMMANDATIONS D'AM√âLIORATION :")
    recommandations = [
        "Collecter plus de donn√©es authentiques par locuteurs natifs",
        "Inclure plus de variantes dialectales et r√©gionales",
        "D√©velopper des m√©canismes de feedback utilisateur",
        "Int√©grer la d√©tection de discours de haine sp√©cifique au contexte",
        "Cr√©er des interfaces en langues locales",
        "√âtablir des partenariats avec les communaut√©s linguistiques"
    ]
    
    for (i, rec) in enumerate(recommandations)
        println("$i. $rec")
    end
    
    # Estimation √©conomique
    println("\nüí∞ IMPACT √âCONOMIQUE ESTIM√â :")
    println("R√©duction co√ªts mod√©ration : 40-60%")
    println("Am√©lioration temps de r√©ponse : 80-90%")
    println("Accessibilit√© services num√©riques : +300%")
    
    println("\n" * "=" * 50)
end

# Ex√©cution de l'√©valuation
evaluer_impact_societal()
```

**üéØ D√©fi Final :** Proposez 3 am√©liorations concr√®tes pour rendre ce syst√®me plus adapt√© au contexte burkinab√®.

---

## üéØ Exercices Suppl√©mentaires

### Exercice A: D√©tection de code-switching
```julia
# D√©veloppez un mod√®le pour d√©tecter quand les utilisateurs m√©langent les langues
```

### Exercice B: Classification fine par dialecte
```julia
# Affinez le mod√®le pour distinguer les variantes r√©gionales (Moor√© du Centre vs Nord)
```

### Exercice C: D√©tection d'√©motion avanc√©e
```julia
# √âtendez la classification au-del√† de positif/n√©gatif (joie, col√®re, peur, tristesse)
```

### Exercice D: Mod√®le de g√©n√©ration de texte
```julia
# Cr√©ez un g√©n√©rateur simple de messages dans les langues locales
```

## üèÜ Points Cl√©s Appris
- ‚úÖ Cr√©ation de corpus multilingues pour langues locales
- ‚úÖ Extraction de features textuelles discriminantes
- ‚úÖ Classification multi-classe pour d√©tection de langue
- ‚úÖ Analyse de sentiment en contexte multilingue
- ‚úÖ Syst√®mes de mod√©ration automatique de contenu
- ‚úÖ D√©tection d'urgence et priorisation de messages
- ‚úÖ Traitement en lot pour analyse de r√©seaux sociaux
- ‚úÖ √âvaluation de l'impact soci√©tal des syst√®mes ML
- ‚úÖ Consid√©rations √©thiques en NLP multilingue
- ‚úÖ Applications pratiques pour le d√©veloppement local

Ce syst√®me de classification multilingue ouvre de nombreuses possibilit√©s pour am√©liorer la communication num√©rique au Burkina Faso et pr√©server les langues nationales dans l'√®re digitale !